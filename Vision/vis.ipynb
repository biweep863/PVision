{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# ------------------------------\n",
    "# Step 1: Dataset Augmentation\n",
    "# ------------------------------\n",
    "\n",
    "# Data Augmentation Generator with Reduced Geometry Impact\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,       # Reduced rotation\n",
    "    width_shift_range=0.2,   # Smaller horizontal shift\n",
    "    height_shift_range=0.2,  # Smaller vertical shift\n",
    "    shear_range=0.2,         # Reduced shear\n",
    "    zoom_range=0.1,          # Minor zoom variation\n",
    "    horizontal_flip=True,    # Keep horizontal flips\n",
    "    vertical_flip=False,     # Remove vertical flips\n",
    "    brightness_range=[0.7, 1.3],  # Slight brightness variation\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\"\"\"\n",
    "def add_shadow(img):\n",
    "    rows, cols = img.shape\n",
    "    shadow = np.ones_like(img) * 255  # White base canvas\n",
    "\n",
    "    shadow_type = random.choice([\"ellipse\", \"rectangle\", \"polygon\"])\n",
    "    if shadow_type == \"ellipse\":\n",
    "        center = (random.randint(0, cols), random.randint(0, rows))\n",
    "        axes = (random.randint(20, cols // 3), random.randint(20, rows // 3))\n",
    "        angle = random.randint(0, 360)\n",
    "        cv2.ellipse(shadow, center, axes, angle, 0, 360, (random.randint(50, 100)), -1)\n",
    "    elif shadow_type == \"rectangle\":\n",
    "        x1, y1 = random.randint(0, cols // 2), random.randint(0, rows // 2)\n",
    "        x2, y2 = random.randint(cols // 2, cols), random.randint(rows // 2, rows)\n",
    "        cv2.rectangle(shadow, (x1, y1), (x2, y2), (random.randint(50, 100)), -1)\n",
    "    elif shadow_type == \"polygon\":\n",
    "        num_points = random.randint(4, 8)\n",
    "        points = np.array([[(random.randint(0, cols), random.randint(0, rows)) for _ in range(num_points)]], dtype=np.int32)\n",
    "        cv2.fillPoly(shadow, points, (random.randint(50, 100)))\n",
    "\n",
    "    shadow = cv2.GaussianBlur(shadow, (25, 25), 0)\n",
    "    alpha = random.uniform(0.5, 0.7)\n",
    "    shadow_overlay = cv2.addWeighted(img, 1 - alpha, shadow, alpha, 0)\n",
    "\n",
    "    noise = np.random.normal(0, 10, img.shape).astype(np.float32)\n",
    "    noise = np.clip(noise, 0, 255).astype(np.uint8)\n",
    "    shadow_with_noise = cv2.add(shadow_overlay, noise)\n",
    "\n",
    "    return np.clip(shadow_with_noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "def manual_augmentation(img, output_dir, prefix, start_index, num_images, is_blank=False):\n",
    "\n",
    "    def center_and_fit(rotated_img, target_size=(64, 64)):\n",
    "        # Center the rotated letter and resize moderately to fit the target canvas.\n",
    "        coords = cv2.findNonZero(255 - rotated_img)\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "\n",
    "        # Extract letter and compute scaling factor\n",
    "        letter = rotated_img[y:y+h, x:x+w]\n",
    "        scale = min(target_size[0] / h, target_size[1] / w) * 0.95\n",
    "\n",
    "        # Resize and center the letter on a blank canvas\n",
    "        resized = cv2.resize(letter, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        canvas = np.ones(target_size, dtype=np.uint8) * 255\n",
    "        y_offset = (target_size[0] - resized.shape[0]) // 2\n",
    "        x_offset = (target_size[1] - resized.shape[1]) // 2\n",
    "        canvas[y_offset:y_offset+resized.shape[0], x_offset:x_offset+resized.shape[1]] = resized\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    rows, cols = img.shape\n",
    "    for i in range(num_images):\n",
    "        # Start with a larger canvas\n",
    "        canvas_size = 128\n",
    "        canvas = np.ones((canvas_size, canvas_size), dtype=np.uint8) * 255\n",
    "        y_offset = (canvas_size - rows) // 2\n",
    "        x_offset = (canvas_size - cols) // 2\n",
    "        canvas[y_offset:y_offset+rows, x_offset:x_offset+cols] = img\n",
    "\n",
    "        # Moderate random rotation (-15° to 15°)\n",
    "        angle = random.randint(-15, 15)\n",
    "        M = cv2.getRotationMatrix2D((canvas_size // 2, canvas_size // 2), angle, 1.0)\n",
    "        rotated_img = cv2.warpAffine(canvas, M, (canvas_size, canvas_size), borderMode=cv2.BORDER_CONSTANT, borderValue=255)\n",
    "\n",
    "        # Fit and center the letter\n",
    "        final_img = center_and_fit(rotated_img, target_size=(64, 64))\n",
    "\n",
    "        # Add shadows only for \"white\" class\n",
    "        if is_blank:\n",
    "            final_img = add_shadow(final_img)\n",
    "\n",
    "        save_path = os.path.join(output_dir, f\"{prefix}_{start_index + i}.jpg\")\n",
    "        cv2.imwrite(save_path, final_img)\n",
    "\"\"\"\n",
    "\n",
    "def manual_augmentation(img, output_dir, prefix, start_index, num_images, is_blank=False):\n",
    "    \"\"\"\n",
    "    Perform manual augmentations with texture, lighting, and noise enhancements.\n",
    "    \"\"\"\n",
    "    def center_and_fit(rotated_img, target_size=(64, 64)):\n",
    "        \"\"\" Center and scale the letter to fit within the target canvas. \"\"\"\n",
    "        coords = cv2.findNonZero(255 - rotated_img)\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        letter = rotated_img[y:y+h, x:x+w]\n",
    "        scale = min(target_size[0] / h, target_size[1] / w) * 0.9\n",
    "        resized = cv2.resize(letter, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        canvas = np.ones(target_size, dtype=np.uint8) * 255\n",
    "        y_offset = (target_size[0] - resized.shape[0]) // 2\n",
    "        x_offset = (target_size[1] - resized.shape[1]) // 2\n",
    "        canvas[y_offset:y_offset+resized.shape[0], x_offset:x_offset+resized.shape[1]] = resized\n",
    "        return canvas\n",
    "\n",
    "    rows, cols = img.shape\n",
    "    for i in range(num_images):\n",
    "        # Start with a larger canvas\n",
    "        canvas_size = 128\n",
    "        canvas = np.ones((canvas_size, canvas_size), dtype=np.uint8) * 255\n",
    "        y_offset = (canvas_size - rows) // 2\n",
    "        x_offset = (canvas_size - cols) // 2\n",
    "        canvas[y_offset:y_offset+rows, x_offset:x_offset+cols] = img\n",
    "\n",
    "        # Apply rotation\n",
    "        angle = random.randint(-60, 60)\n",
    "        M = cv2.getRotationMatrix2D((canvas_size // 2, canvas_size // 2), angle, 1.0)\n",
    "        rotated_img = cv2.warpAffine(canvas, M, (canvas_size, canvas_size), borderMode=cv2.BORDER_CONSTANT, borderValue=255)\n",
    "\n",
    "        # Add lighting variations\n",
    "        alpha = random.uniform(0.8, 1.2)  # Contrast control\n",
    "        beta = random.randint(-40, 40)    # Brightness control\n",
    "        lighting_adjusted = cv2.convertScaleAbs(rotated_img, alpha=alpha, beta=beta)\n",
    "\n",
    "        # Add Gaussian noise\n",
    "        noise = np.random.normal(0, 10, lighting_adjusted.shape).astype(np.uint8)\n",
    "        noisy_img = cv2.add(lighting_adjusted, noise)\n",
    "\n",
    "        # Add textures for \"white\" class (or as noise)\n",
    "        if is_blank:\n",
    "            texture = np.random.randint(200, 255, noisy_img.shape, dtype=np.uint8)\n",
    "            texture = cv2.GaussianBlur(texture, (11, 11), 5)\n",
    "            noisy_img = cv2.addWeighted(noisy_img, 0.8, texture, 0.2, 0)\n",
    "\n",
    "        # Center and fit the letter\n",
    "        final_img = center_and_fit(noisy_img, target_size=(64, 64))\n",
    "\n",
    "        # Save augmented image\n",
    "        save_path = os.path.join(output_dir, f\"{prefix}_{start_index + i}.jpg\")\n",
    "        cv2.imwrite(save_path, final_img)\n",
    "\n",
    "def augment_and_save(image_path, output_dir, prefix, total_images=500, is_blank=False):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Error: Image not found at {image_path}\")\n",
    "        return\n",
    "\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    img = img.reshape((1,) + img.shape + (1,))\n",
    "    letter_folder = os.path.join(output_dir, prefix.upper())\n",
    "    os.makedirs(letter_folder, exist_ok=True)\n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(img, batch_size=1, save_prefix=None, save_format='jpg'):\n",
    "        save_path = os.path.join(letter_folder, f\"{prefix}_{i}.jpg\")\n",
    "        cv2.imwrite(save_path, (batch[0, :, :, 0] * 255).astype(np.uint8))\n",
    "        i += 1\n",
    "        if i >= total_images // 2:\n",
    "            break\n",
    "\n",
    "    manual_augmentation(img[0, :, :, 0], letter_folder, prefix, start_index=i, num_images=total_images // 2, is_blank=is_blank)\n",
    "\n",
    "# Generate Dataset\n",
    "original_image_dir = \"original_images\"\n",
    "augmented_image_dir = \"augmented_images_2000\"\n",
    "os.makedirs(augmented_image_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(original_image_dir):\n",
    "    if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "        is_blank = True if \"white\" in filename.lower() else False\n",
    "        augment_and_save(os.path.join(original_image_dir, filename), augmented_image_dir, filename.split('.')[0], 500, is_blank)\n",
    "\n",
    "print(\"Dataset augmentation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tflite_model_maker import image_classifier, model_spec\n",
    "from tflite_model_maker.config import QuantizationConfig, ExportFormat\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure TensorFlow 2.x is being used\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Dataset Preparation\n",
    "# ------------------------------\n",
    "\n",
    "# Paths\n",
    "data_dir = \"augmented_images_2000\"  # Replace with your dataset path\n",
    "img_size = 64  # Image size for resizing\n",
    "batch_size = 16  # Batch size for training\n",
    "\n",
    "# Load dataset into DataLoader with augmentation\n",
    "train_data = DataLoader.from_folder(data_dir)\n",
    "train_data = train_data.split(0.8)  # 80% Training, 20% Validation\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: Train the Model Using TFLite Model Maker\n",
    "# ------------------------------\n",
    "\n",
    "# Select the model architecture: EfficientNet-Lite0 is the default\n",
    "spec = model_spec.get(\"efficientnet_lite0\")\n",
    "\n",
    "# Train the model\n",
    "model = image_classifier.create(\n",
    "    train_data=train_data[0],\n",
    "    validation_data=train_data[1],\n",
    "    model_spec=spec,\n",
    "    epochs=30,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: Evaluate the Model\n",
    "# ------------------------------\n",
    "\n",
    "# Evaluate on the validation set\n",
    "loss, accuracy = model.evaluate(train_data[1])\n",
    "print(f\"Validation Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Step 4: Export the Model\n",
    "# ------------------------------\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_filename = \"letter_classification_model.tflite\"\n",
    "model.export(\n",
    "    export_dir=\".\",\n",
    "    export_format=[ExportFormat.TFLITE, ExportFormat.LABEL]\n",
    ")\n",
    "print(f\"Model exported as {tflite_filename}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Step 5: Visualize Predictions\n",
    "# ------------------------------\n",
    "\n",
    "# Function to display predictions\n",
    "def predict_image(image_path, model):\n",
    "    \"\"\"\n",
    "    Load and predict a single image using the TFLite model.\n",
    "    \"\"\"\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_size, img_size))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    predictions = model.predict_top_k(image_path, k=4)  # Show top 4 predictions\n",
    "    for i, (label, prob) in enumerate(predictions):\n",
    "        print(f\"{i+1}. {label} ({prob:.2%})\")\n",
    "\n",
    "# Test the model with an example image\n",
    "test_image_path = \"H_test.JPG\"  # Replace with your test image path\n",
    "predict_image(test_image_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Load the Trained PyTorch Model\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the CNN Model Architecture (must match the trained model)\n",
    "# Adjusted Model Definition\n",
    "class LetterClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LetterClassificationModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=1),  # conv_layers.0\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),  # conv_layers.2\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1),  # conv_layers.4\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),  # conv_layers.6\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16, 128),  # fc_layers.0\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 4)  # fc_layers.2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LetterClassificationModel().to(device)\n",
    "\n",
    "# Load State Dict\n",
    "model_path = \"letter_classification_with_white.pth\"\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Fix Strict Loading by Ignoring Missing Keys (if necessary)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: Preprocess the Image\n",
    "# ------------------------------\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image, preprocess it to grayscale, resize it, and normalize for PyTorch.\n",
    "    \"\"\"\n",
    "    # Load the image with OpenCV as grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Error: Image not found at {image_path}\")\n",
    "\n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "\n",
    "    # Normalize and convert to tensor\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to range [0,1]\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "    ])\n",
    "    img_tensor = transform(img_resized).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    return img_tensor.to(device), img_resized\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: Make Prediction\n",
    "# ------------------------------\n",
    "def predict_image(image_path, model, class_labels):\n",
    "    \"\"\"\n",
    "    Predict the class of an input image and display it with the result.\n",
    "    Print confidence percentages for all classes.\n",
    "    \"\"\"\n",
    "    # Preprocess the image\n",
    "    img_tensor, img_display = preprocess_image(image_path)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.softmax(outputs[0], dim=0).cpu().numpy()\n",
    "\n",
    "    # Get predicted class\n",
    "    predicted_class_index = np.argmax(probabilities)\n",
    "    predicted_class = class_labels[predicted_class_index]\n",
    "    confidence = probabilities[predicted_class_index] * 100\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(img_display, cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {predicted_class} ({confidence:.2f}%)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print confidence percentages for all classes\n",
    "    print(\"Class Confidence Percentages:\")\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        print(f\"{class_label}: {probabilities[i] * 100:.2f}%\")\n",
    "\n",
    "    print(f\"\\nFinal Prediction: {predicted_class} with {confidence:.2f}% confidence.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Step 4: Test the Model with a Photo\n",
    "# ------------------------------\n",
    "# Define class labels (must match the order of training)\n",
    "class_labels = [\"H\", \"S\", \"U\", \"White\"]  # Include \"White\" as the fourth class\n",
    "\n",
    "# Test Image Path\n",
    "test_image_path = \"S.png\"  # Replace with your actual image path\n",
    "\n",
    "# Predict and Display\n",
    "predict_image(test_image_path, model, class_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
